{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Introduction to Recommendation Systems - PART 2\n",
    "## Item-Based CF, Comparisons, and Broader AI Connections\n",
    "\n",
    "**CCO 460 - Inteligencia Artificial**  \n",
    "**Universidad del Sagrado Coraz√≥n**  \n",
    "**Lesson 2 of 2**\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Today's Learning Objectives\n",
    "\n",
    "By the end of this lesson, students will understand:\n",
    "\n",
    "1. **How** item-based collaborative filtering differs from user-based\n",
    "2. **When** to choose user-based vs item-based approaches\n",
    "3. **How** recommendation systems connect to broader AI (neural networks, deep learning)\n",
    "4. **What** statistical foundations underpin collaborative filtering\n",
    "5. **How** to evaluate recommendation system performance\n",
    "\n",
    "---\n",
    "\n",
    "## üóÇÔ∏è Lesson 2 Outline\n",
    "\n",
    "1. [Quick Review of Part 1](#1.-Quick-Review)\n",
    "2. [Item-Based Collaborative Filtering](#2.-Item-Based-CF)\n",
    "3. [Comparison: User-Based vs Item-Based](#3.-Comparison)\n",
    "4. [Connections to Broader AI](#4.-AI-Connections)\n",
    "5. [Statistical Foundations](#5.-Statistical-Foundations)\n",
    "6. [Complete Glossary](#6.-Glossary)\n",
    "7. [Summary and Wrap-Up](#7.-Summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Quick Review of Part 1\n",
    "\n",
    "## üìù What We Learned\n",
    "\n",
    "### User-Based Collaborative Filtering: \"People like you also liked...\"\n",
    "\n",
    "**The Algorithm:**\n",
    "1. **Find similar users** ‚Üí Compare target user with all others using cosine similarity\n",
    "2. **Get their preferences** ‚Üí Look at movies similar users rated highly\n",
    "3. **Make recommendations** ‚Üí Recommend top-rated movies (weighted by similarity)\n",
    "\n",
    "**Key Concepts:**\n",
    "- **User-Item Matrix:** Rows = users, Columns = movies, Values = ratings\n",
    "- **Sparsity:** Most values are missing (users rate few movies)\n",
    "- **Cosine Similarity:** Measures angle between user rating vectors\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "cos(Œ∏) = (A ¬∑ B) / (||A|| √ó ||B||)\n",
    "```\n",
    "\n",
    "**Intuition:** Users with similar rating patterns = similar taste\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Discussion Questions (5 minutes)\n",
    "\n",
    "**For the Class:**\n",
    "1. What are the main advantages of user-based CF?\n",
    "2. What challenges might arise with millions of users?\n",
    "3. What happens when a new user joins (cold start problem)?\n",
    "\n",
    "**Teaching Note:** Use this as a transition to item-based CF, which addresses some of these challenges.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Item-Based Collaborative Filtering\n",
    "\n",
    "## üéØ Core Idea: \"Because you watched...\"\n",
    "\n",
    "**User-Based:** Find similar **people**  \n",
    "**Item-Based:** Find similar **items (movies)**\n",
    "\n",
    "### The Algorithm:\n",
    "\n",
    "**Step 1: Calculate Item Similarity**\n",
    "- Compare every movie with every other movie\n",
    "- Based on how users rated them\n",
    "- Movies rated similarly by many users ‚Üí similar movies\n",
    "\n",
    "**Step 2: Find User's Favorites**\n",
    "- Look at movies the target user rated highly\n",
    "\n",
    "**Step 3: Recommend Similar Items**\n",
    "- Find movies similar to user's favorites\n",
    "- Recommend those the user hasn't seen yet\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Conceptual Example\n",
    "\n",
    "**Jane's Ratings:**\n",
    "- The Godfather: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5.0)\n",
    "- Star Wars: ‚≠ê‚≠ê‚≠ê‚≠ê (4.0)\n",
    "\n",
    "**Item Similarity (pre-computed):**\n",
    "\n",
    "| Movie | Similar To Godfather | Similar To Star Wars |\n",
    "|-------|---------------------|---------------------|\n",
    "| Godfather Part II | 0.95 | 0.45 |\n",
    "| Scarface | 0.88 | 0.32 |\n",
    "| Empire Strikes Back | 0.42 | 0.97 |\n",
    "| Frozen | 0.15 | 0.20 |\n",
    "\n",
    "**Recommendations:**\n",
    "1. **Godfather Part II** (very similar to Godfather, which Jane loved)\n",
    "2. **Empire Strikes Back** (very similar to Star Wars, which Jane liked)\n",
    "3. **Scarface** (similar to Godfather)\n",
    "\n",
    "**Teaching Note:** Emphasize that we're comparing ITEMS, not USERS. The similarity is based on co-ratings.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries and load data from Part 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")\n",
    "print(\"\\nNote: Make sure you've completed Part 1 or have the data files ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MovieLens data (same as Part 1)\n",
    "try:\n",
    "    movies = pd.read_csv('movies.csv')\n",
    "    ratings = pd.read_csv('ratings.csv')\n",
    "    data = pd.merge(movies, ratings, on='movieId')\n",
    "    \n",
    "    user_item_matrix = data.pivot_table(\n",
    "        index='userId',\n",
    "        columns='title',\n",
    "        values='rating'\n",
    "    )\n",
    "    \n",
    "    user_item_matrix_filled = user_item_matrix.fillna(0)\n",
    "    \n",
    "    print(\"‚úÖ Data loaded and prepared!\")\n",
    "    print(f\"   - Matrix shape: {user_item_matrix.shape}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: Data files not found\")\n",
    "    print(\"   Please download MovieLens from: https://grouplens.org/datasets/movielens/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ The Key Difference: Matrix Transpose\n",
    "\n",
    "**User-Based:**\n",
    "- Calculate similarity between **rows** (users)\n",
    "- Matrix: users √ó movies\n",
    "\n",
    "**Item-Based:**\n",
    "- Calculate similarity between **columns** (movies)\n",
    "- Matrix: movies √ó users (transposed!)\n",
    "\n",
    "### Visualization:\n",
    "\n",
    "```\n",
    "USER-BASED (users √ó movies):\n",
    "          Movie1  Movie2  Movie3\n",
    "User1       5       4       3\n",
    "User2       4       5       4    ‚Üê Compare ROWS\n",
    "User3       3       4       5\n",
    "\n",
    "ITEM-BASED (movies √ó users):\n",
    "          User1  User2  User3\n",
    "Movie1      5      4      3\n",
    "Movie2      4      5      4    ‚Üê Compare ROWS (which are movies!)\n",
    "Movie3      3      4      5\n",
    "```\n",
    "\n",
    "**Teaching Note:** This is a critical concept. Draw on the board to show the transpose operation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ITEM-ITEM similarity matrix\n",
    "print(\"üîÑ Calculating item-item similarities...\")\n",
    "print(\"   This compares every movie with every other movie\")\n",
    "print(f\"   {user_item_matrix.shape[1]:,} movies ‚Üí {user_item_matrix.shape[1]**2:,} comparisons!\")\n",
    "\n",
    "# CRITICAL: Transpose the matrix so movies are rows\n",
    "item_similarity = cosine_similarity(user_item_matrix_filled.T)\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity,\n",
    "    index=user_item_matrix.columns,  # Movie titles\n",
    "    columns=user_item_matrix.columns  # Movie titles\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Item similarity matrix created: {item_similarity_df.shape}\")\n",
    "print(\"   Each cell shows how similar two movies are (0 to 1)\")\n",
    "\n",
    "# Show sample similarities for a popular movie\n",
    "sample_movie = \"Godfather, The (1972)\"\n",
    "\n",
    "if sample_movie in item_similarity_df.index:\n",
    "    print(f\"\\nüìã Movies most similar to '{sample_movie}':\")\n",
    "    similar = item_similarity_df[sample_movie].sort_values(ascending=False)\n",
    "    for i, (movie, sim) in enumerate(similar.head(10).items(), 1):\n",
    "        if i == 1:\n",
    "            print(f\"{i:2d}. {movie[:60]:<60} {sim:.3f} (itself)\")\n",
    "        else:\n",
    "            print(f\"{i:2d}. {movie[:60]:<60} {sim:.3f}\")\n",
    "else:\n",
    "    print(f\"\\nNote: '{sample_movie}' not found, using first movie as example\")\n",
    "    sample_movie = item_similarity_df.index[0]\n",
    "    print(f\"\\nüìã Movies most similar to '{sample_movie}':\")\n",
    "    similar = item_similarity_df[sample_movie].sort_values(ascending=False)\n",
    "    for i, (movie, sim) in enumerate(similar.head(10).items(), 1):\n",
    "        print(f\"{i:2d}. {movie[:60]:<60} {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize item similarity distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Get upper triangle to avoid counting each pair twice\n",
    "similarities = item_similarity_df.values[np.triu_indices_from(item_similarity_df.values, k=1)]\n",
    "\n",
    "plt.hist(similarities, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Cosine Similarity', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Item-Item Similarities', fontsize=14, fontweight='bold')\n",
    "plt.axvline(similarities.mean(), color='red', linestyle='--', label=f'Mean: {similarities.mean():.3f}')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Item Similarity Statistics:\")\n",
    "print(f\"   - Mean: {similarities.mean():.3f}\")\n",
    "print(f\"   - Median: {np.median(similarities):.3f}\")\n",
    "print(f\"   - Std Dev: {similarities.std():.3f}\")\n",
    "print(f\"\\nüí° Most movies have low similarity (expected - diverse catalog)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Implementation: Item-Based Recommendation Functions\n",
    "\n",
    "We'll implement two functions:\n",
    "1. **Find similar movies** to a given movie\n",
    "2. **Recommend movies for a user** based on items they liked\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_movies(movie_title, similarity_matrix, n_recommendations=10):\n",
    "    \"\"\"\n",
    "    Find movies similar to a given movie.\n",
    "    \n",
    "    This is the core of item-based CF: finding similar items.\n",
    "    \n",
    "    Args:\n",
    "        movie_title: Title of the reference movie\n",
    "        similarity_matrix: Item-item similarity scores (movies √ó movies)\n",
    "        n_recommendations: Number of similar movies to return\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with similar movie titles and similarity scores\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if movie_title not in similarity_matrix.index:\n",
    "        raise ValueError(f\"Movie '{movie_title}' not found in dataset\")\n",
    "    \n",
    "    # Get similarity scores for this movie\n",
    "    movie_similarities = similarity_matrix[movie_title]\n",
    "    \n",
    "    # Sort by similarity (descending)\n",
    "    similar_movies = movie_similarities.sort_values(ascending=False)\n",
    "    \n",
    "    # Remove the movie itself (similarity = 1.0)\n",
    "    similar_movies = similar_movies[similar_movies.index != movie_title]\n",
    "    \n",
    "    # Return top N\n",
    "    return similar_movies.head(n_recommendations)\n",
    "\n",
    "print(\"‚úÖ Function 1: recommend_similar_movies() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies_item_based(user_id, user_item_matrix, similarity_matrix, \n",
    "                                n_recommendations=10, min_rating=4.0):\n",
    "    \"\"\"\n",
    "    Generate movie recommendations for a user using Item-Based CF.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Find movies the user rated highly (>= min_rating)\n",
    "    2. For each highly-rated movie, find similar movies\n",
    "    3. Aggregate scores (weighted by user's rating and similarity)\n",
    "    4. Recommend highest-scoring unwatched movies\n",
    "    \n",
    "    Args:\n",
    "        user_id: Target user ID\n",
    "        user_item_matrix: User-item rating matrix (filled with 0s)\n",
    "        similarity_matrix: Item-item similarity scores\n",
    "        n_recommendations: Number of movies to recommend\n",
    "        min_rating: Threshold for \"highly rated\" (default: 4.0)\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with movie titles and predicted scores\n",
    "    \"\"\"\n",
    "    # Validation\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        raise ValueError(f\"User {user_id} not found in dataset\")\n",
    "    \n",
    "    # Step 1: Get user's ratings\n",
    "    user_ratings = user_item_matrix.loc[user_id]\n",
    "    \n",
    "    # Step 2: Find highly-rated movies\n",
    "    highly_rated = user_ratings[user_ratings >= min_rating]\n",
    "    \n",
    "    if len(highly_rated) == 0:\n",
    "        # User hasn't rated anything highly\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    # Step 3: Aggregate similarity scores\n",
    "    recommendation_scores = pd.Series(0.0, index=user_item_matrix.columns)\n",
    "    \n",
    "    for movie, rating in highly_rated.items():\n",
    "        # Get movies similar to this one\n",
    "        similar_movies = similarity_matrix[movie]\n",
    "        \n",
    "        # Weight by user's rating (movies they loved contribute more)\n",
    "        weighted_similarities = similar_movies * rating\n",
    "        \n",
    "        # Add to total scores\n",
    "        recommendation_scores += weighted_similarities\n",
    "    \n",
    "    # Step 4: Remove movies already rated by user\n",
    "    rated_movies = user_ratings[user_ratings > 0].index\n",
    "    recommendations = recommendation_scores.drop(rated_movies, errors='ignore')\n",
    "    \n",
    "    # Step 5: Return top N\n",
    "    return recommendations.sort_values(ascending=False).head(n_recommendations)\n",
    "\n",
    "print(\"‚úÖ Function 2: recommend_movies_item_based() defined\")\n",
    "print(\"\\nBoth functions ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Find similar movies\n",
    "test_movie = \"Star Wars (1977)\"\n",
    "\n",
    "# Check if movie exists\n",
    "if test_movie not in item_similarity_df.index:\n",
    "    # Try alternative title\n",
    "    alternatives = [m for m in item_similarity_df.index if 'Star Wars' in m]\n",
    "    if alternatives:\n",
    "        test_movie = alternatives[0]\n",
    "    else:\n",
    "        test_movie = item_similarity_df.index[10]  # Use any movie\n",
    "\n",
    "print(f\"üé¨ Finding movies similar to '{test_movie}'...\\n\")\n",
    "\n",
    "similar_movies = recommend_similar_movies(test_movie, item_similarity_df, n_recommendations=10)\n",
    "\n",
    "print(f\"Top 10 movies similar to '{test_movie}':\")\n",
    "print(\"=\"*80)\n",
    "for i, (movie, similarity) in enumerate(similar_movies.items(), 1):\n",
    "    print(f\"{i:2d}. {movie[:60]:<60} Similarity: {similarity:.3f}\")\n",
    "\n",
    "print(\"\\nüí° Notice: Similar movies often share genre, director, or era!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Generate recommendations for a user\n",
    "test_user = 1\n",
    "\n",
    "print(f\"üé¨ Generating item-based recommendations for User {test_user}...\\n\")\n",
    "\n",
    "# First, show what this user has rated highly\n",
    "user_ratings = user_item_matrix.loc[test_user]\n",
    "highly_rated = user_ratings[user_ratings >= 4.0].sort_values(ascending=False)\n",
    "\n",
    "print(f\"üìã User {test_user}'s Highly-Rated Movies (>= 4.0):\")\n",
    "print(\"=\"*80)\n",
    "for i, (movie, rating) in enumerate(highly_rated.head(10).items(), 1):\n",
    "    stars = '‚≠ê' * int(rating)\n",
    "    print(f\"{i:2d}. {movie[:55]:<55} {stars} ({rating})\")\n",
    "if len(highly_rated) > 10:\n",
    "    print(f\"    ... and {len(highly_rated)-10} more movies\")\n",
    "\n",
    "# Generate recommendations\n",
    "item_recommendations = recommend_movies_item_based(\n",
    "    test_user,\n",
    "    user_item_matrix_filled,\n",
    "    item_similarity_df,\n",
    "    n_recommendations=10,\n",
    "    min_rating=4.0\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Item-Based Recommendations for User {test_user}:\")\n",
    "print(\"=\"*80)\n",
    "for i, (movie, score) in enumerate(item_recommendations.items(), 1):\n",
    "    print(f\"{i:2d}. {movie[:60]:<60} Score: {score:.3f}\")\n",
    "\n",
    "print(\"\\nüí° These are based on movies similar to what the user already loved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Comparison: User-Based vs Item-Based\n",
    "\n",
    "## üìä Side-by-Side Comparison\n",
    "\n",
    "Let's compare both methods for the same user:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user-based recommendations (from Part 1)\n",
    "def recommend_movies_user_based(user_id, matrix, similarity_matrix, n=10, n_neighbors=10):\n",
    "    \"\"\"\n",
    "    User-Based CF (from Part 1).\n",
    "    \"\"\"\n",
    "    if user_id not in similarity_matrix.index:\n",
    "        raise ValueError(f\"User {user_id} not found\")\n",
    "    \n",
    "    user_similarities = similarity_matrix.loc[user_id]\n",
    "    similar_users_indices = user_similarities.sort_values(ascending=False).index[1:n_neighbors+1]\n",
    "    similar_users_ratings = matrix.loc[similar_users_indices]\n",
    "    similarity_weights = user_similarities.loc[similar_users_indices]\n",
    "    \n",
    "    weighted_sum = similar_users_ratings.T.dot(similarity_weights)\n",
    "    total_weight = similarity_weights.sum()\n",
    "    \n",
    "    if total_weight > 0:\n",
    "        predicted_ratings = weighted_sum / total_weight\n",
    "    else:\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    user_rated_movies = matrix.loc[user_id]\n",
    "    user_rated_movies = user_rated_movies[user_rated_movies > 0].index\n",
    "    recommendations = predicted_ratings.drop(user_rated_movies, errors='ignore')\n",
    "    \n",
    "    return recommendations.sort_values(ascending=False).head(n)\n",
    "\n",
    "# Calculate user similarity matrix\n",
    "user_similarity = cosine_similarity(user_item_matrix_filled)\n",
    "user_similarity_df = pd.DataFrame(\n",
    "    user_similarity,\n",
    "    index=user_item_matrix.index,\n",
    "    columns=user_item_matrix.index\n",
    ")\n",
    "\n",
    "print(\"‚úÖ User-based function ready for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate both types of recommendations\n",
    "comparison_user = 1\n",
    "\n",
    "user_based_recs = recommend_movies_user_based(\n",
    "    comparison_user,\n",
    "    user_item_matrix_filled,\n",
    "    user_similarity_df,\n",
    "    n=10\n",
    ")\n",
    "\n",
    "item_based_recs = recommend_movies_item_based(\n",
    "    comparison_user,\n",
    "    user_item_matrix_filled,\n",
    "    item_similarity_df,\n",
    "    n_recommendations=10\n",
    ")\n",
    "\n",
    "print(f\"üîç COMPARISON FOR USER {comparison_user}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüë• USER-BASED CF (People like you also liked...):\")\n",
    "print(\"-\"*80)\n",
    "for i, (movie, score) in enumerate(user_based_recs.head(10).items(), 1):\n",
    "    print(f\"{i:2d}. {movie[:65]:<65} {score:.3f}\")\n",
    "\n",
    "print(\"\\nüé¨ ITEM-BASED CF (Because you watched...):\")\n",
    "print(\"-\"*80)\n",
    "for i, (movie, score) in enumerate(item_based_recs.head(10).items(), 1):\n",
    "    print(f\"{i:2d}. {movie[:65]:<65} {score:.3f}\")\n",
    "\n",
    "# Find overlap\n",
    "overlap = set(user_based_recs.index) & set(item_based_recs.index)\n",
    "print(f\"\\nüìå Overlap: {len(overlap)} movies appear in both lists\")\n",
    "if overlap:\n",
    "    print(\"   Movies in both:\", list(overlap)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã When to Use Which?\n",
    "\n",
    "### User-Based CF: \"People like you also liked...\"\n",
    "\n",
    "**Best for:**\n",
    "- Small to medium number of users\n",
    "- User preferences change frequently\n",
    "- Want serendipitous recommendations (discovery)\n",
    "- Social platforms (\"friends also liked\")\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ Better for discovery (finds unexpected matches)\n",
    "- ‚úÖ Captures evolving trends (user taste changes reflected)\n",
    "- ‚úÖ Can explain: \"Users like you enjoyed this\"\n",
    "\n",
    "**Challenges:**\n",
    "- ‚ùå Computationally expensive (O(users¬≤))\n",
    "- ‚ùå Doesn't scale to millions of users\n",
    "- ‚ùå Similarity matrix changes frequently\n",
    "- ‚ùå Cold start: new users have no history\n",
    "\n",
    "---\n",
    "\n",
    "### Item-Based CF: \"Because you watched...\"\n",
    "\n",
    "**Best for:**\n",
    "- Large number of users\n",
    "- Stable item catalog\n",
    "- E-commerce (product recommendations)\n",
    "- Streaming services (Netflix, Spotify)\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ Scales better (O(items¬≤), usually items << users)\n",
    "- ‚úÖ Item similarities are stable (can pre-compute)\n",
    "- ‚úÖ Faster recommendations (lookup vs computation)\n",
    "- ‚úÖ Can explain: \"Similar to movies you loved\"\n",
    "\n",
    "**Challenges:**\n",
    "- ‚ùå Less serendipitous (stays in same genre/style)\n",
    "- ‚ùå Filter bubble (reinforces existing preferences)\n",
    "- ‚ùå Cold start: new items have no ratings\n",
    "- ‚ùå Popularity bias (popular items dominate)\n",
    "\n",
    "---\n",
    "\n",
    "## üè¢ Real-World Usage\n",
    "\n",
    "| Company | Primary Approach | Why? |\n",
    "|---------|-----------------|------|\n",
    "| **Amazon** | Item-Based | Billions of users, stable products |\n",
    "| **Netflix** | Hybrid (both) | Started item-based, now uses neural networks |\n",
    "| **Spotify** | Hybrid + Deep Learning | Combines CF with audio features |\n",
    "| **YouTube** | Item-Based + Neural Nets | Millions of users, billions of videos |\n",
    "| **Facebook** | User-Based (social graph) | Social connections are key |\n",
    "\n",
    "**Teaching Note:** Discuss why each company chose their approach. What are their constraints?\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Hybrid Approaches\n",
    "\n",
    "Most production systems combine both:\n",
    "\n",
    "1. **Weighted Hybrid:** Average scores from both methods\n",
    "2. **Switching Hybrid:** Use user-based for new users, item-based for established\n",
    "3. **Cascade Hybrid:** Use user-based first, item-based for tie-breaking\n",
    "4. **Feature Augmentation:** Use CF outputs as features for ML model\n",
    "\n",
    "**See AI Explorer:** `/recommendation-systems` ‚Üí Hybrid Systems for more details\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Connections to Broader AI\n",
    "\n",
    "## üß† How Recommendation Systems Fit in AI\n",
    "\n",
    "Collaborative filtering is part of a larger AI ecosystem:\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Evolution of Recommendation Systems\n",
    "\n",
    "### **1990s: Rule-Based & Content Filtering**\n",
    "- Manual rules: \"If user liked action, recommend action\"\n",
    "- Content-based: Match item features\n",
    "- **Limitation:** Doesn't discover unexpected preferences\n",
    "\n",
    "### **2000s: Collaborative Filtering (What We Learned!)**\n",
    "- User-based and item-based CF\n",
    "- Matrix factorization (SVD, ALS)\n",
    "- **Breakthrough:** Netflix Prize (2006-2009)\n",
    "- **Limitation:** Cold start, sparsity\n",
    "\n",
    "### **2010s: Neural Networks & Deep Learning**\n",
    "- Deep neural collaborative filtering\n",
    "- Autoencoders for recommendations\n",
    "- Sequence models (RNNs, LSTMs)\n",
    "- **Advantage:** Learn complex patterns\n",
    "\n",
    "### **2020s: Transformers & Large Models**\n",
    "- Transformer-based recommenders\n",
    "- Multi-modal (text, images, audio)\n",
    "- Personalized language models\n",
    "- **Example:** YouTube, TikTok, Instagram feeds\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Connection 1: Matrix Factorization\n",
    "\n",
    "**Core Idea:** Decompose the user-item matrix into latent factors\n",
    "\n",
    "```\n",
    "Rating Matrix (users √ó items) = User Features √ó Item Features\n",
    "    1000 √ó 5000              =    1000 √ó 50    √ó   50 √ó 5000\n",
    "```\n",
    "\n",
    "**Latent Factors** might represent:\n",
    "- Genre preferences (action, drama, comedy)\n",
    "- Time period (classic, modern)\n",
    "- Intensity (cerebral vs. action-packed)\n",
    "- Visual style (dark vs. bright)\n",
    "\n",
    "**Techniques:**\n",
    "- **SVD (Singular Value Decomposition)**\n",
    "- **ALS (Alternating Least Squares)**\n",
    "- **NMF (Non-negative Matrix Factorization)**\n",
    "\n",
    "**Connection to AI:** This is unsupervised learning - finding hidden structure in data!\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Connection 2: Neural Collaborative Filtering\n",
    "\n",
    "**Evolution:** Replace dot product with neural network\n",
    "\n",
    "**Traditional CF:**\n",
    "```\n",
    "rating = user_vector ¬∑ item_vector\n",
    "```\n",
    "\n",
    "**Neural CF:**\n",
    "```\n",
    "rating = NeuralNetwork(user_embedding, item_embedding)\n",
    "```\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "User ID ‚Üí Embedding Layer ‚Üí \\\n",
    "                             ‚Üí Concatenate ‚Üí Hidden Layers ‚Üí Output (rating)\n",
    "Item ID ‚Üí Embedding Layer ‚Üí /\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- Learns non-linear relationships\n",
    "- Can incorporate side information (user age, item genre)\n",
    "- Flexible architecture\n",
    "\n",
    "**See AI Explorer:** `/recommendation-systems` ‚Üí Neural Networks for implementation examples\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Connection 3: Deep Learning Evolution\n",
    "\n",
    "### **Autoencoders for Recommendations**\n",
    "- Compress user-item interactions\n",
    "- Denoise sparse ratings\n",
    "- Generate recommendations from reconstructed matrix\n",
    "\n",
    "### **Recurrent Neural Networks (RNNs)**\n",
    "- Model sequential behavior: \"What will user watch next?\"\n",
    "- Capture temporal patterns\n",
    "- Used in: YouTube, Netflix (session-based)\n",
    "\n",
    "### **Transformers**\n",
    "- Self-attention mechanism\n",
    "- Capture long-range dependencies\n",
    "- Multi-modal: combine text, images, metadata\n",
    "- Used in: Modern recommender systems (2020+)\n",
    "\n",
    "### **Reinforcement Learning**\n",
    "- Maximize long-term engagement (not just next click)\n",
    "- Exploration vs. exploitation\n",
    "- Used in: TikTok, Instagram feeds\n",
    "\n",
    "---\n",
    "\n",
    "## üß© How It All Connects\n",
    "\n",
    "```\n",
    "Classical ML Foundation:\n",
    "‚îú‚îÄ‚îÄ k-Nearest Neighbors (k-NN) ‚Üí User/Item similarity\n",
    "‚îú‚îÄ‚îÄ Linear Algebra ‚Üí Matrix operations, SVD\n",
    "‚îú‚îÄ‚îÄ Optimization ‚Üí Gradient descent, ALS\n",
    "‚îî‚îÄ‚îÄ Statistics ‚Üí Correlation, regression\n",
    "\n",
    "                    ‚Üì\n",
    "\n",
    "Collaborative Filtering (What We Learned!):\n",
    "‚îú‚îÄ‚îÄ User-Based CF\n",
    "‚îú‚îÄ‚îÄ Item-Based CF\n",
    "‚îî‚îÄ‚îÄ Matrix Factorization\n",
    "\n",
    "                    ‚Üì\n",
    "\n",
    "Neural Networks:\n",
    "‚îú‚îÄ‚îÄ Neural Collaborative Filtering\n",
    "‚îú‚îÄ‚îÄ Autoencoders\n",
    "‚îú‚îÄ‚îÄ RNNs / LSTMs\n",
    "‚îî‚îÄ‚îÄ Transformers\n",
    "\n",
    "                    ‚Üì\n",
    "\n",
    "Modern AI Systems:\n",
    "‚îú‚îÄ‚îÄ Hybrid models (CF + Deep Learning)\n",
    "‚îú‚îÄ‚îÄ Multi-modal recommendations\n",
    "‚îú‚îÄ‚îÄ Reinforcement learning\n",
    "‚îî‚îÄ‚îÄ Personalized LLMs\n",
    "```\n",
    "\n",
    "**Key Insight:** Collaborative filtering is not obsolete! It's a building block:\n",
    "- Used in **ensemble models** with neural networks\n",
    "- Provides **interpretable baselines**\n",
    "- Works well for **cold-start** scenarios (new deep models need data)\n",
    "- **Computationally efficient** for many use cases\n",
    "\n",
    "**Teaching Note:** Emphasize that students are learning foundational concepts that scale to modern AI.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Statistical Foundations\n",
    "\n",
    "## üìä The Math Behind Collaborative Filtering\n",
    "\n",
    "CF is built on classical statistics and machine learning concepts:\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Correlation and Similarity\n",
    "\n",
    "### **Cosine Similarity (What We Used)**\n",
    "```\n",
    "cos(Œ∏) = (A ¬∑ B) / (||A|| √ó ||B||)\n",
    "```\n",
    "- Measures angle between vectors\n",
    "- Range: 0 to 1 (for ratings)\n",
    "- **Advantage:** Ignores magnitude (harsh/lenient raters)\n",
    "\n",
    "### **Pearson Correlation**\n",
    "```\n",
    "r = Œ£(x·µ¢ - xÃÑ)(y·µ¢ - »≥) / ‚àö[Œ£(x·µ¢ - xÃÑ)¬≤ √ó Œ£(y·µ¢ - »≥)¬≤]\n",
    "```\n",
    "- Measures linear relationship\n",
    "- Range: -1 to 1\n",
    "- **Advantage:** Centers data (removes rating bias)\n",
    "\n",
    "### **Jaccard Similarity**\n",
    "```\n",
    "J(A,B) = |A ‚à© B| / |A ‚à™ B|\n",
    "```\n",
    "- Measures set overlap\n",
    "- Range: 0 to 1\n",
    "- **Advantage:** Works with binary data (liked/not liked)\n",
    "\n",
    "### **Euclidean Distance**\n",
    "```\n",
    "d = ‚àö[Œ£(x·µ¢ - y·µ¢)¬≤]\n",
    "Similarity = 1 / (1 + d)\n",
    "```\n",
    "- Geometric distance\n",
    "- **Advantage:** Intuitive, works well with dense data\n",
    "\n",
    "**Connection:** These are all distance/similarity metrics from **clustering** and **classification**!\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ k-Nearest Neighbors (k-NN)\n",
    "\n",
    "**CF is essentially k-NN applied to ratings:**\n",
    "\n",
    "**User-Based CF:**\n",
    "1. Find k most similar users ‚Üí k-nearest neighbors in user space\n",
    "2. Aggregate their ratings ‚Üí weighted average\n",
    "3. Predict target user's rating ‚Üí classification/regression\n",
    "\n",
    "**Item-Based CF:**\n",
    "1. Find k most similar items ‚Üí k-nearest neighbors in item space\n",
    "2. Aggregate user's ratings on similar items ‚Üí weighted average\n",
    "3. Predict rating for new item ‚Üí regression\n",
    "\n",
    "**Parameters:**\n",
    "- `k` = number of neighbors (we used 10)\n",
    "- Distance metric = cosine similarity\n",
    "- Weighting = by similarity score\n",
    "\n",
    "**Connection:** This is supervised learning (predict ratings) using unsupervised learning (find neighbors)!\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Regression and Prediction\n",
    "\n",
    "**CF is a regression problem:**\n",
    "\n",
    "**Goal:** Predict missing ratings\n",
    "```\n",
    "rÃÇ·µ§·µ¢ = predicted rating for user u on item i\n",
    "```\n",
    "\n",
    "**User-Based Prediction:**\n",
    "```\n",
    "rÃÇ·µ§·µ¢ = (Œ£ sim(u,v) √ó r·µ•·µ¢) / Œ£ sim(u,v)\n",
    "```\n",
    "Where:\n",
    "- `sim(u,v)` = similarity between users u and v\n",
    "- `r·µ•·µ¢` = rating by user v on item i\n",
    "- Sum over k most similar users\n",
    "\n",
    "**Item-Based Prediction:**\n",
    "```\n",
    "rÃÇ·µ§·µ¢ = (Œ£ sim(i,j) √ó r·µ§‚±º) / Œ£ sim(i,j)\n",
    "```\n",
    "Where:\n",
    "- `sim(i,j)` = similarity between items i and j\n",
    "- `r·µ§‚±º` = rating by user u on item j\n",
    "- Sum over k most similar items\n",
    "\n",
    "**This is weighted average regression!**\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Bayesian Interpretation\n",
    "\n",
    "**CF can be viewed through Bayesian lens:**\n",
    "\n",
    "**Question:** What's the probability user u will like item i?\n",
    "\n",
    "**Bayes' Theorem:**\n",
    "```\n",
    "P(like i | user u) = P(user u | like i) √ó P(like i) / P(user u)\n",
    "```\n",
    "\n",
    "**User-Based CF as Bayes:**\n",
    "- **Prior:** What do similar users like?\n",
    "- **Likelihood:** How similar are they?\n",
    "- **Posterior:** Predicted rating\n",
    "\n",
    "**Connection to Probabilistic Models:**\n",
    "- Bayesian networks\n",
    "- Latent factor models\n",
    "- Probabilistic matrix factorization\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Matrix Decomposition (SVD)\n",
    "\n",
    "**Singular Value Decomposition:**\n",
    "\n",
    "```\n",
    "R = U √ó Œ£ √ó V·µÄ\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `R` = rating matrix (users √ó items)\n",
    "- `U` = user feature matrix (users √ó latent factors)\n",
    "- `Œ£` = singular values (importance of factors)\n",
    "- `V` = item feature matrix (items √ó latent factors)\n",
    "\n",
    "**Interpretation:**\n",
    "- Each user represented by k latent features\n",
    "- Each item represented by k latent features\n",
    "- Rating = dot product of feature vectors\n",
    "\n",
    "**Dimensionality Reduction:**\n",
    "- Reduce from 1000s of items to ~50 latent factors\n",
    "- Captures 90% of variance with 5% of dimensions\n",
    "- Removes noise from sparse data\n",
    "\n",
    "**Connection:** Same technique used in:\n",
    "- Principal Component Analysis (PCA)\n",
    "- Image compression\n",
    "- Natural language processing (LSA)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ How Statistics Connect to Modern AI\n",
    "\n",
    "**Classical Statistics ‚Üí CF ‚Üí Neural Networks:**\n",
    "\n",
    "1. **Correlation** ‚Üí Cosine similarity ‚Üí Attention mechanisms (transformers)\n",
    "2. **k-NN** ‚Üí User/Item CF ‚Üí Graph neural networks\n",
    "3. **Regression** ‚Üí Rating prediction ‚Üí Neural regression\n",
    "4. **Bayesian** ‚Üí Probabilistic CF ‚Üí Variational autoencoders\n",
    "5. **SVD** ‚Üí Matrix factorization ‚Üí Embedding layers\n",
    "\n",
    "**Teaching Note:** Show how classical statistics are foundational to modern deep learning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Complete Glossary\n",
    "\n",
    "## üìñ Comprehensive Reference\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Core Concepts\n",
    "\n",
    "**Collaborative Filtering (CF)**  \n",
    "Making predictions about user preferences by leveraging collective patterns from many users.\n",
    "\n",
    "**User-Item Matrix**  \n",
    "A matrix where rows represent users, columns represent items, and values are ratings. Most cells are empty (sparse).\n",
    "\n",
    "**Sparsity**  \n",
    "The proportion of missing values in the user-item matrix. Real-world datasets are 95-99% sparse.\n",
    "\n",
    "**Cold Start Problem**  \n",
    "Difficulty making recommendations for new users (no history) or new items (no ratings).\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Similarity Metrics\n",
    "\n",
    "**Cosine Similarity**  \n",
    "Measures the angle between two vectors. Range: 0 to 1 (for ratings). Formula: `cos(Œ∏) = (A¬∑B) / (||A|| √ó ||B||)`\n",
    "\n",
    "**Pearson Correlation**  \n",
    "Measures linear correlation, accounting for rating bias. Range: -1 to 1. Centers data around mean.\n",
    "\n",
    "**Jaccard Similarity**  \n",
    "Measures set overlap. Best for binary data (liked/not liked). Formula: `|A‚à©B| / |A‚à™B|`\n",
    "\n",
    "**Euclidean Distance**  \n",
    "Straight-line distance in multi-dimensional space. Convert to similarity: `1/(1+distance)`\n",
    "\n",
    "**Manhattan Distance**  \n",
    "Sum of absolute differences. Also called L1 distance or taxicab distance.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Evaluation Metrics\n",
    "\n",
    "**Mean Absolute Error (MAE)**  \n",
    "Average absolute difference between predicted and actual ratings. Lower is better. Formula: `Œ£|predicted - actual| / n`\n",
    "\n",
    "**Root Mean Square Error (RMSE)**  \n",
    "Square root of average squared errors. Penalizes large errors more. Formula: `‚àö(Œ£(predicted - actual)¬≤ / n)`\n",
    "\n",
    "**Precision**  \n",
    "Proportion of recommended items that user actually liked. Formula: `(relevant ‚à© recommended) / recommended`\n",
    "\n",
    "**Recall**  \n",
    "Proportion of liked items that were recommended. Formula: `(relevant ‚à© recommended) / relevant`\n",
    "\n",
    "**F1 Score**  \n",
    "Harmonic mean of precision and recall. Formula: `2 √ó (precision √ó recall) / (precision + recall)`\n",
    "\n",
    "**Mean Reciprocal Rank (MRR)**  \n",
    "Average of reciprocal ranks of first relevant item. Rewards getting relevant items at top of list.\n",
    "\n",
    "**Normalized Discounted Cumulative Gain (NDCG)**  \n",
    "Measures ranking quality, accounting for position. Higher-ranked relevant items contribute more.\n",
    "\n",
    "**Coverage**  \n",
    "Percentage of items that can be recommended. Measures how well system uses full catalog.\n",
    "\n",
    "**Diversity**  \n",
    "Variety in recommendations. Avoids recommending only popular or similar items.\n",
    "\n",
    "**Serendipity**  \n",
    "Ability to recommend unexpected but relevant items. Balances accuracy with discovery.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Techniques and Algorithms\n",
    "\n",
    "**User-Based CF**  \n",
    "Find similar users, recommend what they liked. Formula: `rating = Œ£(sim √ó rating) / Œ£sim`\n",
    "\n",
    "**Item-Based CF**  \n",
    "Find similar items, recommend based on user's favorites. More scalable than user-based.\n",
    "\n",
    "**Matrix Factorization**  \n",
    "Decompose rating matrix into user and item feature matrices. Examples: SVD, ALS, NMF.\n",
    "\n",
    "**Singular Value Decomposition (SVD)**  \n",
    "Linear algebra technique that finds latent factors. `R = U √ó Œ£ √ó V·µÄ`\n",
    "\n",
    "**Alternating Least Squares (ALS)**  \n",
    "Iterative optimization for matrix factorization. Alternates between fixing user/item factors.\n",
    "\n",
    "**k-Nearest Neighbors (k-NN)**  \n",
    "Find k most similar users/items. CF is essentially k-NN applied to ratings.\n",
    "\n",
    "**Content-Based Filtering**  \n",
    "Recommend based on item features (genre, director, etc.). Doesn't require other users' data.\n",
    "\n",
    "**Hybrid Methods**  \n",
    "Combine multiple approaches (CF + content-based + demographic). Used by most production systems.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Advanced Concepts\n",
    "\n",
    "**Neural Collaborative Filtering**  \n",
    "Replace dot product with neural network. Learns non-linear relationships.\n",
    "\n",
    "**Autoencoders**  \n",
    "Neural networks that compress and reconstruct user-item matrix. Denoises sparse data.\n",
    "\n",
    "**Recurrent Neural Networks (RNN)**  \n",
    "Model sequential behavior. Captures temporal patterns: \"What will user watch next?\"\n",
    "\n",
    "**Transformers**  \n",
    "Self-attention mechanism. Captures long-range dependencies. State-of-the-art for many tasks.\n",
    "\n",
    "**Reinforcement Learning**  \n",
    "Maximize long-term engagement, not just immediate clicks. Exploration vs. exploitation.\n",
    "\n",
    "**Embedding**  \n",
    "Dense vector representation of users/items. Learned from data, captures latent features.\n",
    "\n",
    "**Attention Mechanism**  \n",
    "Weights different inputs by importance. Core component of transformers.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Challenges and Issues\n",
    "\n",
    "**Cold Start**  \n",
    "New users/items have no history. Solutions: content-based, demographic, hybrid.\n",
    "\n",
    "**Sparsity**  \n",
    "Most users rate few items. Solutions: matrix factorization, implicit feedback.\n",
    "\n",
    "**Scalability**  \n",
    "Computing similarity for millions of users/items. Solutions: sampling, approximate methods, item-based CF.\n",
    "\n",
    "**Filter Bubble**  \n",
    "Recommendations reinforce existing preferences. Users stuck in narrow content. Solutions: diversity, serendipity metrics.\n",
    "\n",
    "**Popularity Bias**  \n",
    "System over-recommends popular items. Long-tail items ignored. Solutions: regularization, re-ranking.\n",
    "\n",
    "**Shilling Attacks**  \n",
    "Malicious users create fake ratings to boost/demote items. Solutions: anomaly detection, robust similarity.\n",
    "\n",
    "**Privacy**  \n",
    "Recommendations reveal user preferences. Solutions: differential privacy, federated learning.\n",
    "\n",
    "**Fairness**  \n",
    "System may discriminate against certain groups/items. Solutions: fairness-aware algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Related Concepts from Other AI Areas\n",
    "\n",
    "**Clustering**  \n",
    "Group similar users/items. Related to CF's similarity computation.\n",
    "\n",
    "**Classification**  \n",
    "Predict categories (liked/disliked). Binary recommendation problem.\n",
    "\n",
    "**Regression**  \n",
    "Predict continuous values (ratings). Core of CF prediction.\n",
    "\n",
    "**Dimensionality Reduction**  \n",
    "Reduce features while preserving information. PCA, SVD, autoencoders.\n",
    "\n",
    "**Natural Language Processing (NLP)**  \n",
    "Process text features (reviews, descriptions). Word embeddings similar to user/item embeddings.\n",
    "\n",
    "**Computer Vision**  \n",
    "Process visual features (movie posters, product images). CNNs for visual recommendations.\n",
    "\n",
    "**Graph Neural Networks**  \n",
    "Model user-item interactions as graph. Captures multi-hop relationships.\n",
    "\n",
    "**Transfer Learning**  \n",
    "Use knowledge from one domain in another. Cross-domain recommendations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Summary and Wrap-Up\n",
    "\n",
    "## üéØ What We Learned (Both Parts)\n",
    "\n",
    "### **Part 1: User-Based Collaborative Filtering**\n",
    "- ‚úÖ Understanding the recommendation problem\n",
    "- ‚úÖ Creating and analyzing user-item matrices\n",
    "- ‚úÖ Calculating user-user similarity with cosine\n",
    "- ‚úÖ Implementing user-based recommendations\n",
    "- ‚úÖ Working with MovieLens dataset\n",
    "\n",
    "### **Part 2: Item-Based CF and Beyond**\n",
    "- ‚úÖ Item-based collaborative filtering\n",
    "- ‚úÖ Comparing user-based vs item-based approaches\n",
    "- ‚úÖ Connections to broader AI (neural networks, transformers)\n",
    "- ‚úÖ Statistical foundations (k-NN, regression, Bayesian)\n",
    "- ‚úÖ Complete glossary of metrics and techniques\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Key Takeaways\n",
    "\n",
    "### 1. **Two Main Approaches**\n",
    "- **User-Based:** \"People like you also liked...\" ‚Üí Better discovery\n",
    "- **Item-Based:** \"Because you watched...\" ‚Üí More scalable\n",
    "\n",
    "### 2. **Real Systems Use Hybrids**\n",
    "- Combine CF with content-based filtering\n",
    "- Layer neural networks on top of CF\n",
    "- Balance accuracy, diversity, serendipity\n",
    "\n",
    "### 3. **CF is Foundational**\n",
    "- Connects to k-NN, regression, clustering\n",
    "- Evolved into neural collaborative filtering\n",
    "- Still used in production systems today\n",
    "\n",
    "### 4. **Challenges Remain**\n",
    "- Cold start problem\n",
    "- Sparsity and scalability\n",
    "- Filter bubbles and fairness\n",
    "- Privacy concerns\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps for Students\n",
    "\n",
    "### **Practice:**\n",
    "1. Implement both methods from scratch (Assignment 7)\n",
    "2. Experiment with different similarity metrics\n",
    "3. Try matrix factorization (SVD)\n",
    "4. Build a hybrid recommender\n",
    "\n",
    "### **Explore:**\n",
    "1. **AI Explorer** ‚Üí `/recommendation-systems` for interactive demos\n",
    "2. Try Surprise library (Python) for advanced CF\n",
    "3. Read Netflix Prize papers (groundbreaking work)\n",
    "4. Explore modern neural recommenders (PyTorch, TensorFlow)\n",
    "\n",
    "### **Real-World Projects:**\n",
    "1. Build a movie recommender with web interface\n",
    "2. Create music playlist generator\n",
    "3. Implement product recommendations for e-commerce\n",
    "4. Build a book/article recommendation system\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "### **Datasets:**\n",
    "- MovieLens: https://grouplens.org/datasets/movielens/\n",
    "- Amazon Reviews: https://cseweb.ucsd.edu/~jmcauley/datasets.html\n",
    "- Last.fm Music: http://ocelma.net/MusicRecommendationDataset/\n",
    "- Book-Crossing: http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
    "\n",
    "### **Libraries:**\n",
    "- Surprise: http://surpriselib.com/ (collaborative filtering)\n",
    "- LightFM: https://github.com/lyst/lightfm (hybrid recommenders)\n",
    "- RecBole: https://recbole.io/ (comprehensive toolkit)\n",
    "- Implicit: https://github.com/benfred/implicit (fast CF)\n",
    "\n",
    "### **Papers to Read:**\n",
    "1. \"Item-Based Collaborative Filtering\" (Sarwar et al., 2001)\n",
    "2. \"Matrix Factorization Techniques\" (Koren et al., 2009)\n",
    "3. \"Neural Collaborative Filtering\" (He et al., 2017)\n",
    "4. \"Deep Learning based Recommender Systems\" (Zhang et al., 2019)\n",
    "\n",
    "### **AI Explorer Pages:**\n",
    "- `/recommendation-systems` ‚Üí Complete guide with interactive examples\n",
    "- `/neural-networks` ‚Üí Foundation for advanced recommenders\n",
    "- `/machine-learning` ‚Üí Related ML concepts\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Final Discussion Questions\n",
    "\n",
    "**For the Class (15 minutes):**\n",
    "\n",
    "1. **Ethics:** Should recommendation systems prioritize engagement or user well-being? (e.g., YouTube recommending conspiracy theories)\n",
    "\n",
    "2. **Privacy:** How much should systems know about you to make good recommendations? Where's the line?\n",
    "\n",
    "3. **Filter Bubbles:** Do recommendations trap us in echo chambers? How can we design for diversity?\n",
    "\n",
    "4. **Fairness:** Should recommendations be equally good for all users? What about niche interests?\n",
    "\n",
    "5. **Future:** Where are recommendation systems headed? Will transformers replace CF entirely?\n",
    "\n",
    "**Teaching Note:** These questions have no right answers. Encourage debate and critical thinking.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Assignment Preview\n",
    "\n",
    "**Assignment 7: Collaborative Filtering Implementation**\n",
    "\n",
    "You will:\n",
    "1. Implement user-based CF from scratch (30 pts)\n",
    "2. Implement item-based CF from scratch (30 pts)\n",
    "3. Compare both methods (25 pts)\n",
    "4. Analyze limitations and propose improvements (15 pts)\n",
    "\n",
    "**Due:** [See Canvas]\n",
    "\n",
    "**Resources:**\n",
    "- This notebook (reference implementation)\n",
    "- Corrected code file (bug-free version)\n",
    "- AI Explorer (conceptual help)\n",
    "- Office hours (debugging support)\n",
    "\n",
    "---\n",
    "\n",
    "## üé¨ Closing Thoughts\n",
    "\n",
    "**Recommendation systems are everywhere:**\n",
    "- üé¨ What you watch (Netflix, YouTube, TikTok)\n",
    "- üéµ What you listen to (Spotify, Apple Music)\n",
    "- üìö What you read (Amazon, Goodreads)\n",
    "- üõçÔ∏è What you buy (Amazon, eBay)\n",
    "- üë• Who you connect with (Facebook, LinkedIn)\n",
    "- üì∞ What news you see (Google, Twitter)\n",
    "\n",
    "**You now understand how they work!**\n",
    "\n",
    "**From simple collaborative filtering to advanced neural networks, the core ideas remain:**\n",
    "- Learn from collective behavior\n",
    "- Find patterns in data\n",
    "- Predict what people will like\n",
    "- Balance accuracy, diversity, and fairness\n",
    "\n",
    "**As AI engineers, you can:**\n",
    "- Build better recommendation systems\n",
    "- Understand their limitations\n",
    "- Design for ethics and fairness\n",
    "- Push the field forward\n",
    "\n",
    "---\n",
    "\n",
    "## üôè Thank You!\n",
    "\n",
    "**Questions? Comments? Ideas for projects?**\n",
    "\n",
    "**See you in the next lesson!**\n",
    "\n",
    "---\n",
    "\n",
    "**CCO 460 - Inteligencia Artificial**  \n",
    "**Universidad del Sagrado Coraz√≥n**  \n",
    "**End of Lesson 2**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
